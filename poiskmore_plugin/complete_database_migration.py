#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–û–õ–ù–ê–Ø –ú–ò–ì–†–ê–¶–ò–Ø –ë–ê–ó–´ –î–ê–ù–ù–´–• –ü–û–ò–°–ö-–ú–û–†–ï
========================================
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –º–∏–≥—Ä–∞—Ü–∏–∏ –≤—Å–µ—Ö –ë–î –∏ —Ç–∞–±–ª–∏—Ü –ø—Ä–æ–µ–∫—Ç–∞ (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è)

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 2025-01-17
–í–µ—Ä—Å–∏—è: 2.2.3 (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –≤—Å–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏)
"""

import sqlite3
import os
import sys
import json
import xml.etree.ElementTree as ET
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import shutil
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TableMigrator:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü—ã"""
    
    def __init__(self, conn: sqlite3.Connection, table_name: str, schema: str):
        self.conn = conn
        self.table_name = table_name
        self.schema = schema
        
    def migrate(self, old_data: List[Tuple]) -> bool:
        try:
            c = self.conn.cursor()
            c.execute(self.schema)
            
            if old_data:
                placeholders = ','.join(['?'] * len(old_data[0]))
                c.executemany(f"INSERT INTO {self.table_name} VALUES ({placeholders})", old_data)
                
            self.conn.commit()
            return True
        except Exception as e:
            self.conn.rollback()
            logger.error(f"–û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ {self.table_name}: {e}")
            return False
            
    def add_indexes(self, indexes: List[str]):
        c = self.conn.cursor()
        for idx in indexes:
            try:
                c.execute(idx)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å: {e}")
        self.conn.commit()

class DatabaseMigration:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–ª–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏ –ë–î –ü–û–ò–°–ö-–ú–û–†–ï"""
    
    SCHEMA_VERSION = "2.2.3"
    
    DATABASES = {
        'incidents.db': '–û—Å–Ω–æ–≤–Ω–∞—è –ë–î –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤ –∏ –æ–ø–µ—Ä–∞—Ü–∏–π',
        'poiskmore.db': '–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è –ë–î –ø–ª–∞–≥–∏–Ω–∞'
    }
    
    # –°—Ö–µ–º–∞ incidents (50 –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π)
    INCIDENTS_SCHEMA = """
        CREATE TABLE IF NOT EXISTS incidents (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            case_number TEXT UNIQUE NOT NULL,
            weather_data_id TEXT,
            name TEXT NOT NULL,
            object_type TEXT,
            aviation TEXT,
            mmsi TEXT,
            imo TEXT,
            call_sign TEXT,
            board_number TEXT,
            download_size REAL,
            coords_lat REAL NOT NULL CHECK(coords_lat BETWEEN -90 AND 90),
            coords_lon REAL NOT NULL CHECK(coords_lon BETWEEN -180 AND 180),
            last_known_position_lat REAL,
            last_known_position_lon REAL,
            datum_lat REAL,
            datum_lon REAL,
            datetime TEXT NOT NULL,
            datetime_start TEXT,
            datetime_end TEXT,
            datetime_suspended TEXT,
            datetime_reopened TEXT,
            last_contact_time TEXT,
            download_date TEXT,
            description TEXT,
            situation_type TEXT NOT NULL,
            incident_type TEXT,
            help_needed TEXT,
            default_status INTEGER DEFAULT 0,
            status TEXT DEFAULT 'active' CHECK(status IN ('active', 'suspended', 'closed', 'archived')),
            close_reason TEXT,
            suspended_reason TEXT,
            hull_color TEXT,
            superstructure_color TEXT,
            fuel REAL,
            displacement REAL,
            length REAL,
            width REAL,
            draft REAL,
            num_people INTEGER DEFAULT 0,
            persons_rescued INTEGER DEFAULT 0,
            persons_missing INTEGER DEFAULT 0,
            persons_deceased INTEGER DEFAULT 0,
            crew_count INTEGER,
            passengers_count INTEGER,
            contacts TEXT,
            owner_name TEXT,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP,
            updated_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
    """
    
    # –°—Ö–µ–º–∞ sru_resources
    SRU_RESOURCES_SCHEMA = """
        CREATE TABLE IF NOT EXISTS sru_resources (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            type TEXT NOT NULL,
            call_sign TEXT,
            capabilities TEXT,
            max_speed REAL,
            endurance_hours REAL,
            persons_capacity INTEGER,
            status TEXT DEFAULT 'available',
            base_location TEXT,
            current_lat REAL,
            current_lon REAL,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP,
            updated_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
    """
    
    # –°—Ö–µ–º–∞ sru_assignments
    SRU_ASSIGNMENTS_SCHEMA = """
        CREATE TABLE IF NOT EXISTS sru_assignments (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            incident_id INTEGER NOT NULL,
            resource_id INTEGER NOT NULL,
            assignment_time TEXT NOT NULL,
            arrival_time TEXT,
            departure_time TEXT,
            search_pattern TEXT,
            assigned_area TEXT,
            status TEXT DEFAULT 'assigned',
            notes TEXT,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (incident_id) REFERENCES incidents(id),
            FOREIGN KEY (resource_id) REFERENCES sru_resources(id)
        )
    """
    
    def __init__(self, work_dir: str = "."):
        self.work_dir = Path(work_dir).resolve()
        self.db_dir = self.work_dir / "db"
        self.backup_dir = self.work_dir / f"backups/migration_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.log_file = self.backup_dir / 'migration.log'
        self.success_count = 0
        self.warnings = []
        self.errors = []
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ë–î –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        self.db_dir.mkdir(parents=True, exist_ok=True)
        
    def create_backup(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –ë–î"""
        try:
            self.backup_dir.mkdir(parents=True, exist_ok=True)
            
            for db_name in self.DATABASES.keys():
                db_path = self.db_dir / db_name
                if db_path.exists():
                    backup_path = self.backup_dir / f"{db_name}.backup"
                    shutil.copy2(db_path, backup_path)
                    logger.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_path}")
                    
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            self.errors.append(str(e))
            return False
            
    def analyze_database(self, db_path: Path) -> Dict[str, List[str]]:
        """–ê–Ω–∞–ª–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î"""
        structure = {}
        
        if not db_path.exists():
            return structure
            
        try:
            conn = sqlite3.connect(db_path)
            c = conn.cursor()
            
            c.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = c.fetchall()
            
            for table in tables:
                table_name = table[0]
                c.execute(f"PRAGMA table_info({table_name})")
                columns = c.fetchall()
                structure[table_name] = [col[1] for col in columns]
                
            conn.close()
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ë–î: {e}")
            
        return structure
        
    def get_old_data(self, conn: sqlite3.Connection, table_name: str) -> List[Tuple]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å—Ç–∞—Ä–æ–π —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            c = conn.cursor()
            c.execute(f"SELECT * FROM {table_name}")
            return c.fetchall()
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ {table_name}: {e}")
            return []
            
    def copy_data_to_new_table(self, conn: sqlite3.Connection, old_table: str, 
                               new_table: str, columns_mapping: Dict[str, str]) -> bool:
        """–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –º–∞–ø–ø–∏–Ω–≥–æ–º –∫–æ–ª–æ–Ω–æ–∫"""
        try:
            c = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –≤ –Ω–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü–µ
            c.execute(f"PRAGMA table_info({new_table})")
            new_columns = [col[1] for col in c.fetchall()]
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
            select_columns = []
            insert_columns = []
            
            for new_col in new_columns:
                if new_col in columns_mapping:
                    old_col = columns_mapping[new_col]
                    select_columns.append(old_col)
                    insert_columns.append(new_col)
                elif new_col not in ['id', 'created_at', 'updated_at']:
                    select_columns.append('NULL')
                    insert_columns.append(new_col)
                    
            if insert_columns:
                query = f"""
                    INSERT INTO {new_table} ({','.join(insert_columns)})
                    SELECT {','.join(select_columns)} FROM {old_table}
                """
                c.execute(query)
                conn.commit()
                
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False
            
    def create_indexes(self, conn: sqlite3.Connection, table_name: str, indexes: List[str]):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã"""
        c = conn.cursor()
        for idx in indexes:
            try:
                c.execute(idx)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å: {e}")
        conn.commit()
        
    def migrate_incidents_table(self, db_path: Path) -> bool:
        """–ú–∏–≥—Ä–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã incidents"""
        logger.info(f"–ú–∏–≥—Ä–∞—Ü–∏—è incidents –≤ {db_path.name}...")
        
        try:
            conn = sqlite3.connect(db_path)
            
            old_structure = self.analyze_database(db_path)
            has_old_incidents = 'incidents' in old_structure
            
            old_data = []
            if has_old_incidents:
                old_data = self.get_old_data(conn, 'incidents')
                
            c = conn.cursor()
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
            if has_old_incidents:
                c.execute("DROP TABLE IF EXISTS new_incidents")
                c.execute(self.INCIDENTS_SCHEMA.replace('incidents', 'new_incidents'))
                
                # –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫
                columns_mapping = {}
                old_columns = old_structure['incidents']
                for col in old_columns:
                    columns_mapping[col] = col
                    
                self.copy_data_to_new_table(conn, 'incidents', 'new_incidents', columns_mapping)
                
                c.execute("DROP TABLE IF EXISTS incidents")
                c.execute("ALTER TABLE new_incidents RENAME TO incidents")
            else:
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –Ω—É–ª—è
                c.execute(self.INCIDENTS_SCHEMA)
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_incidents_status ON incidents(status)",
                "CREATE INDEX IF NOT EXISTS idx_incidents_datetime ON incidents(datetime)",
                "CREATE INDEX IF NOT EXISTS idx_incidents_coords ON incidents(coords_lat, coords_lon)",
                "CREATE INDEX IF NOT EXISTS idx_incidents_case ON incidents(case_number)"
            ]
            self.create_indexes(conn, 'incidents', indexes)
            
            conn.close()
            self.success_count += 1
            logger.info("–ú–∏–≥—Ä–∞—Ü–∏—è incidents –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ incidents: {e}")
            self.errors.append(str(e))
            return False
            
    def migrate_other_tables(self, db_path: Path) -> bool:
        """–ú–∏–≥—Ä–∞—Ü–∏—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü"""
        tables_schemas = [
            ('sru_resources', self.SRU_RESOURCES_SCHEMA),
            ('sru_assignments', self.SRU_ASSIGNMENTS_SCHEMA)
        ]
        
        try:
            conn = sqlite3.connect(db_path)
            
            for table_name, schema in tables_schemas:
                logger.info(f"–ú–∏–≥—Ä–∞—Ü–∏—è {table_name}...")
                c = conn.cursor()
                c.execute(schema)
                self.success_count += 1
                    
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü: {e}")
            self.errors.append(str(e))
            return False
            
    def parse_csharp_data(self, csharp_dir: Path) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –∏–∑ C# –≤–µ—Ä—Å–∏–∏"""
        data = []
        
        # –ü–∞—Ä—Å–∏–Ω–≥ container.xml
        container_path = csharp_dir / "container.xml"
        if container_path.exists():
            try:
                tree = ET.parse(container_path)
                root = tree.getroot()
                parsed = {child.tag: child.text for child in root}
                data.append(parsed)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ container.xml: {e}")
                
        # –ü–∞—Ä—Å–∏–Ω–≥ JSON —Ñ–∞–π–ª–æ–≤
        for json_file in csharp_dir.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    parsed = json.load(f)
                    if isinstance(parsed, list):
                        data.extend(parsed)
                    else:
                        data.append(parsed)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {json_file}: {e}")
                
        return data
        
    def migrate_from_csharp(self, csharp_dir: str = r'C:\INSTALLPOISKMORE') -> bool:
        """–ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ C# –≤–µ—Ä—Å–∏–∏"""
        logger.info(f"–ú–∏–≥—Ä–∞—Ü–∏—è –∏–∑ C# –¥–∞–Ω–Ω—ã—Ö...")
        csharp_path = Path(csharp_dir)
        
        if not csharp_path.exists():
            logger.warning(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è C# –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {csharp_dir}")
            return True
            
        parsed_data = self.parse_csharp_data(csharp_path)
        
        if not parsed_data:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ –∏–∑ C#")
            return True
            
        try:
            db_path = self.db_dir / 'incidents.db'
            conn = sqlite3.connect(db_path)
            c = conn.cursor()
            
            migrated_count = 0
            for item in parsed_data:
                try:
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π case_number –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
                    case_number = item.get('CaseNumber', item.get('id', f'AUTO_{migrated_count:04d}'))
                    name = item.get('Name', item.get('name', 'Unnamed'))
                    
                    c.execute("""
                        INSERT OR IGNORE INTO incidents (
                            case_number, 
                            name, 
                            description,
                            coords_lat,
                            coords_lon,
                            datetime,
                            situation_type
                        )
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """, (
                        case_number,
                        name,
                        item.get('Description', item.get('description', '')),
                        55.0,  # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        37.0,  # –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                        datetime.now().isoformat(),
                        'unknown'
                    ))
                    migrated_count += 1
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—Å—Ç–∞–≤–∏—Ç—å –∑–∞–ø–∏—Å—å: {e}")
                    
            conn.commit()
            conn.close()
            
            if migrated_count > 0:
                logger.info(f"–ú–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ {migrated_count} –∑–∞–ø–∏—Å–µ–π –∏–∑ C#")
                self.success_count += 1
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ –∏–∑ C#: {e}")
            self.errors.append(str(e))
            return False
            
    def verify_migration(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏...")
        
        for db_name in self.DATABASES.keys():
            db_path = self.db_dir / db_name
            if not db_path.exists():
                logger.warning(f"–ë–î –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_path}")
                continue
                
            try:
                conn = sqlite3.connect(db_path)
                c = conn.cursor()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
                c.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [t[0] for t in c.fetchall()]
                
                logger.info(f"–ë–î {db_name} —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–∞–±–ª–∏—Ü—ã: {', '.join(tables)}")
                
                if 'incidents' in tables:
                    c.execute("SELECT COUNT(*) FROM incidents")
                    count = c.fetchone()[0]
                    logger.info(f"  - –¢–∞–±–ª–∏—Ü–∞ incidents —Å–æ–¥–µ—Ä–∂–∏—Ç {count} –∑–∞–ø–∏—Å–µ–π")
                    
                conn.close()
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ {db_name}: {e}")
                self.warnings.append(str(e))
                
        return True
        
    def run_migration(self) -> bool:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏"""
        logger.info("=" * 60)
        logger.info(f"–ú–ò–ì–†–ê–¶–ò–Ø –ë–î –ü–û–ò–°–ö-–ú–û–†–ï v{self.SCHEMA_VERSION}")
        logger.info("=" * 60)
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏
        if not self.create_backup():
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–∏—Ö")
            
        # –ú–∏–≥—Ä–∞—Ü–∏—è –∏–∑ C# –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        self.migrate_from_csharp()
        
        # –ú–∏–≥—Ä–∞—Ü–∏—è –ë–î
        for db_name in self.DATABASES.keys():
            db_path = self.db_dir / db_name
            
            # –°–æ–∑–¥–∞–µ–º –ë–î –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            if not db_path.exists():
                logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –ë–î: {db_path}")
                db_path.parent.mkdir(parents=True, exist_ok=True)
                conn = sqlite3.connect(db_path)
                conn.close()
            
            if not self.migrate_incidents_table(db_path):
                logger.error(f"–û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ {db_name}")
                
            if not self.migrate_other_tables(db_path):
                logger.error(f"–û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü –≤ {db_name}")
                
        # –ü—Ä–æ–≤–µ—Ä–∫–∞
        self.verify_migration()
        
        return len(self.errors) == 0
        
    def print_summary(self):
        """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        print("\n" + "=" * 60)
        print("üìä –ò–¢–û–ì–ò –ú–ò–ì–†–ê–¶–ò–ò")
        print("=" * 60)
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {self.success_count} –æ–ø–µ—Ä–∞—Ü–∏–π")
        print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {len(self.warnings)}")
        print(f"‚ùå –û—à–∏–±–æ–∫: {len(self.errors)}")
        
        if self.warnings:
            print("\n‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
            for i, w in enumerate(self.warnings, 1):
                print(f"  {i}. {w}")
                
        if self.errors:
            print("\n‚ùå –û—à–∏–±–∫–∏:")
            for i, e in enumerate(self.errors, 1):
                print(f"  {i}. {e}")
                
        print("=" * 60)

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    work_dir = sys.argv[1] if len(sys.argv) > 1 else "."
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    if not os.path.exists(work_dir):
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {work_dir}")
        print("–°–æ–∑–¥–∞—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é...")
        os.makedirs(work_dir, exist_ok=True)
        
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏
    migration = DatabaseMigration(work_dir)
    
    print("\n" + "=" * 60)
    print("üöÄ –ú–ò–ì–†–ê–¶–ò–Ø –ë–ê–ó–´ –î–ê–ù–ù–´–• –ü–û–ò–°–ö-–ú–û–†–ï")
    print("=" * 60)
    print(f"üìÅ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {Path(work_dir).resolve()}")
    print(f"üìä –í–µ—Ä—Å–∏—è —Å—Ö–µ–º—ã: {migration.SCHEMA_VERSION}")
    print("-" * 60)
    
    # –ó–∞–ø—Ä–æ—Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
    print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï! –ë—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –º–∏–≥—Ä–∞—Ü–∏—è –ë–î.")
    print("   –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏.")
    response = input("\n‚ùì –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (–¥–∞/yes/y): ").lower()
    
    if response not in ['–¥–∞', 'yes', 'y', '–¥']:
        print("‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 0
        
    # –ó–∞–ø—É—Å–∫ –º–∏–≥—Ä–∞—Ü–∏–∏
    print("\nüîÑ –ù–∞—á–∏–Ω–∞—é –º–∏–≥—Ä–∞—Ü–∏—é...")
    print("-" * 60)
    
    success = migration.run_migration()
    
    # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤
    migration.print_summary()
    
    if success:
        print("\n‚úÖ –ú–ò–ì–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print(f"üìÅ –ë–î –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤: {migration.db_dir}")
        if migration.backup_dir.exists():
            print(f"üíæ –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏: {migration.backup_dir}")
        return 0
    else:
        print("\n‚ùå –ú–ò–ì–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –° –û–®–ò–ë–ö–ê–ú–ò!")
        if migration.backup_dir.exists():
            print(f"üíæ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π: {migration.backup_dir}")
        return 1

if __name__ == "__main__":
    sys.exit(main())